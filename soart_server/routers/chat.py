# soart_server/routers/chat.py

import os
from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from openai import OpenAI
from services.db_service import db_service # ÂØºÂÖ•Êï∞ÊçÆÂ∫ìÊúçÂä°

router = APIRouter(prefix="/api/chat")

# ËæÖÂä©ÂáΩÊï∞ÔºöËé∑ÂèñÈÖçÁΩÆÔºåÂ¶ÇÊûúÊï∞ÊçÆÂ∫ìÊ≤°Â≠òÔºåÂ∞±Áî® .env ÈáåÁöÑ‰øùÂ∫ï
async def get_config(key: str, default: str) -> str:
    val = await db_service.get_setting(key)
    return val if val else os.getenv(key, default)

@router.post("/completions")
async def chat_completions(request: Request):
    try:
        data = await request.json()
        messages = data.get("messages", [])
        
        if not messages:
            raise HTTPException(status_code=400, detail="Messages are required")

        # [‰øÆÊîπ] 1. Âä®ÊÄÅËé∑ÂèñÈÖçÁΩÆ
        api_key = await get_config("API_KEY", "")
        base_url = await get_config("OPENAI_BASE_URL", "https://aihubmix.com/v1")
        default_model = await get_config("DEFAULT_CHAT_MODEL", "gpt-4o")

        # Ê£ÄÊü• Key
        if not api_key:
            raise HTTPException(status_code=500, detail="API Key not configured in settings")

        # [‰øÆÊîπ] 2. Âä®ÊÄÅÂàùÂßãÂåñ Client
        client = OpenAI(api_key=api_key, base_url=base_url)

        # 3. ÂáÜÂ§áÊ®°ÂûãÂèÇÊï∞
        # ÂâçÁ´ØÂèØ‰ª•‰º† model ÂèÇÊï∞ÔºåÂ¶ÇÊûúÊ≤°ÊúâÔºåÂ∞±Áî®Êï∞ÊçÆÂ∫ìÈáåÁöÑÈªòËÆ§ÂÄº
        model = data.get("model") or default_model

        print(f"üí¨ [Chat] Model: {model} | API: {base_url}")

        # 4. Á≥ªÁªüÊèêÁ§∫ËØç
        system_prompt = {
            "role": "system",
            "content": "‰Ω†Âè´ Soart AIÔºåÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑÂàõÊÑèËßÜËßâÂä©Êâã„ÄÇËØ∑Áî®‰∏≠ÊñáÂõûÁ≠î„ÄÇ"
        }
        full_messages = [system_prompt] + messages

        # 5. Ë∞ÉÁî®
        response = client.chat.completions.create(
            model=model,
            messages=full_messages,
            stream=True,
            temperature=0.7
        )

        def event_generator():
            for chunk in response:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if delta.content is not None:
                        yield delta.content

        return StreamingResponse(event_generator(), media_type="text/plain")

    except Exception as e:
        print(f"‚ùå [Chat] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))